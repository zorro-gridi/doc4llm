---
name: md-doc-searcher
description: Search and discover markdown documents in the doc4llm md_docs directory using semantic understanding. Use this skill when Claude needs to find documents matching a query, list available documentation, search document titles by understanding user intent, or discover which documentation sets contain relevant content. Performs comprehensive search across relevant documentation sets and returns exhaustive list of relevant document titles with coverage verification.
allowed-tools:
  - Read
  - Glob
  - Bash
context: fork
---

# Markdown Document Searcher

Search and discover markdown documents in the doc4llm md_docs directory structure using semantic matching.

## Data Flow Integration

**Input Source:** This skill receives **optimized queries from `md-doc-query-optimizer`** skill, not raw user queries.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Query Optimization Phase                  â”‚
â”‚                   (md-doc-query-optimizer)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ 3-5 optimized queries
                            â”‚ with strategy annotations
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Document Discovery Phase                  â”‚
â”‚                      (md-doc-searcher)                       â”‚
â”‚                                                              â”‚
â”‚  Input: Optimized queries from Phase 0                      â”‚
â”‚  Output: Document titles with TOC paths                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Matters:**
- **Multi-perspective search:** Receives 3-5 query variations instead of a single raw query
- **Better recall:** Decomposition, expansion, and translation strategies improve coverage
- **Language handling:** Pre-translated queries (Chineseâ†’English) improve matching accuracy
- **Ambiguity resolution:** Multiple query variants capture different interpretations

## Core Principle

This skill focuses on **document discovery via TOC (Table of Contents)** - finding which documents match your query by searching `docTOC.md` index files.

**CRITICAL:**
- âœ… **DO:** Search `docTOC.md` files and return TOC paths
- âœ… **DO:** Use `grep -B 10` for context when needed (Level 3.2)
- âŒ **DON'T:** Use `Read` tool to load entire `docContent.md` files
- âŒ **DON'T:** Return `docContent.md` paths as primary results

**Workflow:** This skill finds documents â†’ returns `docTOC.md` paths â†’ `md-doc-reader` skill extracts content

This follows the **progressive disclosure** principle: discover structure first (TOC), then access content later.

## Quick Start

When invoked with optimized queries from `md-doc-query-optimizer`, follow this workflow:

**Input:** 3-5 optimized queries (e.g., ["hooks configuration", "setup hooks", "hooks settings"])

1. **List documentation sets** - Use `ls -1 md_docs/` and **filter based on optimized queries**
2. **Select target set(s)** - Choose the most relevant documentation set(s). For generic/cross-cutting queries, consider searching MULTIPLE sets.
3. **List docTOC.md files** - Use `Glob` or `Bash(find)` to find TOC files: `md_docs/<doc_set>/*/docTOC.md`
4. **Read docTOC.md files** - Use `Read` tool to get table of contents for context
5. **Multi-query semantic matching** - Search with ALL optimized queries, aggregate results, deduplicate
6. **Apply progressive fallback** - If Level 1 returns insufficient results, trigger Level 2 (TOC grep) then Level 3 (cross-set + content search with context traceback)
7. **Verify coverage completeness** - CRITICAL: Check if search results are comprehensive. Expand search if gaps exist.
8. **Return comprehensive list** - Provide exhaustive list with TOC paths, coverage notes, and Sources section

**Example:**
```
Input from md-doc-query-optimizer:
  1. "hooks configuration" - translation
  2. "setup hooks" - expansion
  3. "hooks settings" - expansion

Step 1: List and filter doc sets
  â†’ Available: Claude_Code_Docs:latest, Python_Docs:3.11, ...
  â†’ Filter: Optimized queries indicate "hooks" â†’ Select Claude_Code_Docs:latest

Step 2-3: List docTOC.md files in selected set
  â†’ Glob: md_docs/Claude_Code_Docs:latest/*/docTOC.md

Step 4-6: Multi-query search within Claude_Code_Docs:latest
  â†’ Search with query 1: "hooks configuration"
  â†’ Search with query 2: "setup hooks"
  â†’ Search with query 3: "hooks settings"
  â†’ Aggregate and deduplicate results
  â†’ Results:
    - Hooks reference (matched by queries 1, 2, 3)
    - Get started with Claude Code hooks (matched by query 2)
  â†’ TOC Paths returned for md-doc-reader use
```

## Discovery Workflow

### Step 1: Identify Documentation Set with Intent Filtering

First, list available documentation sets and **filter based on user's query intent**:

```bash
# List all available documentation sets
ls -1 md_docs/

# Example output:
# Claude_Code_Docs:latest/
# Python_Docs:3.11/
# React_Docs:v18/
# Another_Doc:v1.0/
```

**Intent-Based Filtering:**
- If user mentions "Claude", "Claude Code" â†’ Filter to `*Claude*` sets
- If user mentions "Python" â†’ Filter to `*Python*` sets
- If user mentions specific framework â†’ Filter to matching sets
- If no specific mention â†’ Ask user to clarify or search all sets

**Examples:**

| User Query | Filter To | Reason |
|------------|-----------|--------|
| "Claude Code ä¸­å…³äº skills çš„æ–‡æ¡£" | `Claude_Code_Docs:latest` | User explicitly mentioned Claude Code |
| "Python å¼‚å¸¸å¤„ç†æ–‡æ¡£" | `*Python*` | User mentioned Python |
| "å¦‚ä½•é…ç½® hooks" | `Claude_Code_Docs:latest` (context) | "hooks" suggests Claude Code context |
| "æ‰€æœ‰å…³äº deployment çš„æ–‡æ¡£" | Ask user | Multiple sets may contain deployment info |

**Commands for filtered listing:**
```bash
# List all sets (for context)
ls -1 md_docs/

# Filter by pattern (e.g., Claude-related)
ls -1 md_docs/ | grep -i claude

# Or use Glob
md_docs/*Claude*/
```

**Important:** Always search within a **specific documentation set** to ensure accurate results. If multiple sets match the query, ask the user to confirm which one to search.

### Step 2: List Document TOC Files in Specified Set

**CRITICAL:** This skill focuses on **document discovery** via TOC files. Always target `docTOC.md` files, NOT directories.

Use `Glob` or `Bash(find)` to discover `docTOC.md` files **within the specified set**:

```bash
# Method 1: Using find to locate TOC files (CORRECT)
find md_docs/Claude_Code_Docs:latest -name "docTOC.md"

# Method 2: Using Glob pattern (CORRECT)
md_docs/Claude_Code_Docs:latest/*/docTOC.md

# âŒ WRONG - Do NOT use directory-only patterns
md_docs/Claude_Code_Docs:latest/*/

# Expected structure:
# md_docs/<doc_name>:<doc_version>/<PageTitle>/docTOC.md
```

**Key points:**
- Always specify `docTOC.md` in the pattern to limit search to TOC files only
- This ensures we're discovering documents through their index/structure, not full content
- Follows **progressive disclosure** principle - TOC first, content later via md-doc-reader

### Step 3: Semantic Matching (via Prompt)

After listing directories, use **semantic understanding via prompt instructions** to match the user's query:

1. **Read docTOC.md files** - For better context, read table of contents from each document
2. **Use new TOC processing utilities** - Extract and match TOC sections using the new utility functions
3. **Semantic matching** - Use your language understanding to match query intent with document content
4. **Return matching directories** - List relevant document paths based on semantic relevance

**Important:** Do NOT rely on simple keyword matching. Use your semantic understanding to:
- Match related concepts (e.g., "configuration" â†’ "settings", "setup")
- Understand domain-specific terminology
- Consider context and user intent

**New in v2.0:** TOC Processing Utilities

The `utils` module now provides enhanced TOC processing functions:

```python
from doc4llm.tool.md_doc_extractor.utils import extract_toc_sections, semantic_match_toc_sections

# Extract sections from docTOC.md content
sections = extract_toc_sections(toc_content, query="hooks", max_sections=20)
# Returns: [{'level': 2, 'title': 'Configure hooks', 'anchor': 'configure-hooks', 'line_number': 5}]

# Or semantic match existing sections
matched = semantic_match_toc_sections(sections, "hooks")
# Returns sections sorted by relevance score
```

**TOC Extraction Workflow:**
1. Read `docTOC.md` file using `Read` tool
2. Parse sections using `extract_toc_sections()` - extracts level, title, anchor, line_number
3. Optionally filter by query or relevance using `semantic_match_toc_sections()`
4. Return matched sections with relevance scores

**Benefits:**
- Structured TOC parsing with metadata
- Semantic matching on section titles
- Anchor link generation for navigation
- Line number tracking for debugging

### Step 3.5: Progressive Fallback Strategy (NEW)

When Level 1 semantic matching returns **0 results OR low-quality matches** (max_similarity < 0.7), automatically invoke fallback levels:

#### Level 1: Semantic Title Matching (Default)
- Current implementation
- Fast path for well-titled documents
- **Quality threshold:** `max_similarity >= 0.7` to return results

#### Level 2: TOC Content Grep (Fallback)

**Trigger:** Level 1 returns 0 results **OR** `max_similarity < 0.7` (low quality matches)

**Command:**
```bash
# Extract core keywords from query and grep TOC files
grep -r -i "core_keyword" md_docs/<doc_set>/*/docTOC.md
```

**Keyword Extraction Rules:**
- Remove stop words: the, a, an, how, to, for, with, by, from, at, on, in, about
- Preserve technical terms: API, hooks, JWT, OAuth, CLI, SDK, HTTP, etc.
- Use root form: configure â†’ config, authenticate â†’ auth, deploy â†’ deployment

**Example:**
```
Query: "how to configure hooks for deployment"
Keywords extracted: configure, hooks, deployment
Grep command: grep -r -iE "(configure|hooks|deployment)" md_docs/<doc_set>/*/docTOC.md
```

#### Level 3: Cross-Set + Content Search (Last Resort)

**Trigger:** Level 2 returns 0 results

**CRITICAL:** This level requires careful relevance filtering and context traceback to avoid meaningless results.

##### Level 3.1: Cross-Set TOC Search (with Relevance Constraints)

**Step 1: Extract domain keywords from user query**
```bash
# Example: User queries "Claude Code skills design philosophy"
# Domain keywords: Claude, Code
# Topic keywords: skills, design, philosophy
```

**Step 2: Filter documentation sets by domain relevance**
```bash
# List all doc sets first
ls -1 md_docs/

# Filter to only relevant sets (e.g., *Claude*, *Code*)
# For "Claude Code skills", only search:
# - Claude_Code_Docs:latest
# NOT: Python_Docs, React_Docs, etc.
```

**Step 3: Search TOC files in filtered sets**
```bash
# Cross-set TOC search WITH domain filter
grep -r -i "keyword" md_docs/*Claude*/docTOC.md md_docs/*Code*/docTOC.md
```

**Why this matters:** Searching "best practices" across ALL doc sets could return Python, React, or other framework-specific practices that are irrelevant to the user's actual query context.

##### Level 3.2: docContent.md Context Search (with Traceback)

**Trigger:** Level 3.1 returns 0 results

**CRITICAL CONSTRAINTS:**
- âŒ **NEVER** use `Read` tool to load entire docContent.md files
- âœ… Only use `grep` with context to extract minimal information
- âœ… Return docTOC.md paths for subsequent use by md-doc-reader

**Search with context traceback:**
```bash
# Use grep -B to get 10 lines of context BEFORE the match
grep -r -i -B 10 "keyword" md_docs/*RelevantSet*/docContent.md
```

**Parse results to extract:**
1. **Documentation set name** - Extract from file path
2. **Document title** - Extract from docContent.md (first 5 lines, look for `#` headings)
3. **Match context** - The 10 lines before the match showing relevant section

**Traceback workflow:**
```bash
# Step 1: Get context from grep (10 lines before match)
grep -r -i -B 10 "design philosophy" md_docs/*Claude*/docContent.md

# Step 2: Parse each result
# Input: md_docs/Claude_Code_Docs:latest/Agent Skills/docContent.md:95: ## How Skills work
# Extract:
#   - Doc set: Claude_Code_Docs:latest
#   - Document: Agent Skills
#   - Title: (from first 5 lines of that docContent.md) â†’ "# Agent Skills"
#   - Context: Lines around the match

# Step 3: If title not found in first 5 lines, retry with more lines
# Retry: Check first 20 lines for title
```

**Return format for Level 3.2:**
```markdown
Found N relevant document(s) via Level 3.2 content search:

1. **Document Title** (Doc_Set:Version)
   - Relevance: Content contains "keyword" in section context
   - Context: [Brief excerpt from grep -B 10 output]
   - TOC Path: `md_docs/<doc_set>/<PageTitle>/docTOC.md`

**Note:** Use `/md-doc-reader "Document Title"` to view full TOC and structure.
```

**âš ï¸ Updated Logic (v2.2):** Level 3 is now split into:
- **Level 3.1:** Cross-set TOC search WITH domain relevance filtering
- **Level 3.2:** Content search with context traceback (grep -B 10, title from 5 lines with retry)

This ensures:
1. Cross-set searches respect the user's query domain (no Python results for Claude queries)
2. Content searches provide proper document attribution without loading full files
3. All results point to docTOC.md for follow-up via md-doc-reader

### Step 4: Delegate to md-doc-reader

Once relevant directories are found, delegate content extraction to `md-doc-reader` skill.

## Semantic Search Instructions

When performing document search, follow these guidelines:

### 1. Intent Filtering at Documentation Set Level

First level of filtering - determine which documentation set to search:

**Filtering Strategies:**

| Strategy | When to Use | Example |
|----------|-------------|---------|
| **Explicit mention** | User names the framework | "Python" â†’ `*Python*` sets |
| **Domain-specific terms** | Unique terminology maps to specific set | "hooks" â†’ Claude Code |
| **Context inference** | Current session context | Previous question about React â†’ React docs |
| **Ask user** | Ambiguous or multiple matches | "deployment" â†’ Ask which project |

**Commands:**
```bash
# List all doc sets
ls -1 md_docs/

# Filter by pattern
ls -1 md_docs/ | grep -i python

# Check if specific set exists
ls -1 md_docs/ | grep -i claude
```

### 2. Use Semantic Understanding, Not Keyword Matching

**âŒ Avoid:** Simple keyword/substring matching
**âœ… Use:** Language understanding to match concepts and context

### 3. Read docTOC.md for Context

Before matching, read the `docTOC.md` file to understand the document structure:
```
Read: md_docs/<doc_set>/<PageTitle>/docTOC.md
```

### 4. Consider Synonyms and Related Concepts

| User Query | Should Match |
|------------|--------------|
| "how to configure" | Settings, Configuration, Setup, Preferences |
| "deployment" | Enterprise deployment, Install, Setup |
| "security" | Authentication, Authorization, Security settings |
| "API" | API reference, Connect, Integration |

### 5. Return Format

Return results as a list of document titles with relevance notes AND coverage verification:

```
Found N relevant document(s) in <doc_set>:

1. **Document Title** - Relevance: why it matches
2. **Another Title** - Relevance: contains section about topic
...

**Coverage:**
- âœ… Covered: [aspects covered by results]
- âš ï¸  Partially covered: [aspects partially covered]
- âŒ Not covered: [aspects that may exist in other documents/sets]
- ğŸ’¡ Suggestion: [if applicable, suggest other searches]
```

**Example with coverage notes:**
```
Found 3 relevant document(s) in Claude_Code_Docs:latest:

1. **Quickstart** - Relevance: Contains "Pro tips for beginners" section
2. **Common workflows** - Relevance: Contains explicit "best practices" guidance
3. **Agent Skills** - Relevance: Covers skill usage best practices

**Coverage:**
- âœ… Covered: Workflow best practices, skill usage patterns
- âš ï¸  Partially covered: Configuration best practices (check Settings doc)
- âŒ Not covered: Performance optimization, security best practices
- ğŸ’¡ Suggestion: Search "performance" or "security" for those topics
```

### 6. Sources Format (ALWAYS REQUIRED)

**CRITICAL:** You MUST include a **Sources** section at the end of ALL search results, regardless of document length or content type.

This ensures proper attribution and allows users to locate the original documents for further reading.

#### Required Format

```markdown

---

### æ–‡æ¡£æ¥æº (Sources)

1. **Document Title**
   - åŸæ–‡é“¾æ¥: https://original-url.com/docs/page
   - TOC è·¯å¾„: `md_docs/<doc_name>:<doc_version>/<PageTitle>/docTOC.md`
```

#### Example

```markdown
Found N relevant document(s):

1. **Common workflows** - Relevance: Contains explicit "best practices" guidance

**Coverage:**
- âœ… Covered: Workflow best practices
- âŒ Not covered: Performance optimization

### æ–‡æ¡£æ¥æº (Sources)

1. **Common workflows**
   - åŸæ–‡é“¾æ¥: https://code.claude.com/docs/en/common-workflows
   - TOC è·¯å¾„: `md_docs/Claude_Code_Docs:latest/Common workflows/docTOC.md`
```

#### How to Get Source Information

1. **Original URL**: Found at the top of docTOC.md:
   ```markdown
   > **åŸæ–‡é“¾æ¥**: https://code.claude.com/docs/en/common-workflows
   ```

2. **Local TOC Path**: `md_docs/<doc_name>:<doc_version>/<PageTitle>/docTOC.md`

**Note:** Use `/md-doc-reader "Document Title"` to view the full TOC and document structure.

## Directory Structure

Expected format:
```
md_docs/
â””â”€â”€ <doc_name>:<doc_version>/
    â””â”€â”€ <PageTitle>/
        â”œâ”€â”€ docContent.md    # Main content
        â””â”€â”€ docTOC.md        # Table of contents
```

Each `<PageTitle>` directory represents one document page.

## Progressive Fallback Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEARCH REQUEST                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Level 1: Title Semantic Match â”‚
              â”‚  - List docTOC.md files       â”‚
              â”‚  - Semantic understanding      â”‚
              â”‚  - Fast: O(k) where k = matchesâ”‚
              â”‚  - Threshold: max_sim >= 0.7   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                               â”‚
        [Results > 0 AND                 [Results = 0 OR
         max_sim >= 0.7]                  max_sim < 0.7]
              â”‚                               â”‚
              â–¼                               â–¼
        To Coverage Check            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  Level 2: TOC Grep Fallback   â”‚
                                    â”‚  - grep -r across TOC files   â”‚
                                    â”‚  - Balanced: O(1) operation   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                   â”‚
                              [Results > 0]      [Results = 0]
                                    â”‚                   â”‚
                                    â–¼                   â–¼
                          To Coverage Check    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                  â”‚  Level 3.1: Cross-Set TOC   â”‚
                                                  â”‚  - Filter by domain        â”‚
                                                  â”‚  - grep -r across filtered â”‚
                                                  â”‚    doc sets                â”‚
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                            â”‚
                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                  â”‚                   â”‚
                                            [Results > 0]      [Results = 0]
                                                  â”‚                   â”‚
                                                  â–¼                   â–¼
                                        To Coverage Check    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                      â”‚  Level 3.2: Content Search â”‚
                                                                      â”‚  - grep -B 10 for context â”‚
                                                                      â”‚  - Extract title from 5   â”‚
                                                                      â”‚    lines (retry: 20)      â”‚
                                                                      â”‚  - Return TOC paths only  â”‚
                                                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                                â”‚
                                                                                â–¼
                                                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                      â”‚   Coverage Completeness â”‚
                                                                      â”‚   Verification Check    â”‚
                                                                      â”‚   - Assess query type   â”‚
                                                                      â”‚   - Check result diversity
                                                                      â”‚   - Identify gaps      â”‚
                                                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                                â”‚
                                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                              â”‚                           â”‚
                                                        [Coverage Complete]          [Gaps Found]
                                                        - Generic queries handled   - Expand scope
                                                        - All aspects covered      - Search other sets
                                                              â”‚                           â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                            â–¼
                                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                              â”‚    Return Results        â”‚
                                                              â”‚    With Coverage Notes   â”‚
                                                              â”‚    - What's covered       â”‚
                                                              â”‚    - What's not           â”‚
                                                              â”‚    + TOC Paths            â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Search Completeness Guidelines

### When is Search Considered Complete?

**CRITICAL:** A search is ONLY complete when you have **verified** that all potentially relevant documents have been found. The progressive fallback strategy finds matches within a scope, but you MUST verify coverage completeness.

#### Completeness Checklist

Before returning results, ask yourself:

- [ ] Have I searched ALL relevant documentation sets?
- [ ] Do the results cover different aspects of the query?
- [ ] Could related concepts exist in documents with different titles?
- [ ] Should I cross-reference with other documentation sets?
- [ ] Have I explicitly stated what is/isn't covered in the results?

#### Multi-Set Search Triggers

**ALWAYS search multiple documentation sets when:**

| Query Pattern | Example | Action | Rationale |
|--------------|---------|--------|-----------|
| Generic concepts | "best practices", "tips", "optimization" | Search ALL doc sets | These concepts apply across multiple domains |
| Cross-cutting concerns | "deployment", "testing", "monitoring", "security" | Search ALL doc sets | May have framework-specific and general implementations |
| Configuration/setup | "how to configure", "setup guide", "getting started" | Search ALL doc sets | Setup varies by framework/context |
| Comparison questions | "difference between X and Y", "X vs Y" | Search ALL doc sets | Requires comprehensive comparison |
| Framework-specific | "React hooks", "Python async", "Claude skills" | Single set | Terminology is domain-specific |

#### Coverage Verification Steps

After completing Level 1-3 search:

1. **Assess result diversity** - Do results cover different perspectives/aspects?
2. **Identify gaps** - What aspects of the query are NOT covered?
3. **Expand if needed** - If gaps found, search other doc sets
4. **Document coverage** - Explicitly state what IS and ISN'T covered

#### Decision Tree: Is Coverage Complete?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     After Level 1-3 Search              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Assess Query Type   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           â”‚
Generic/Cross-cutting    Framework-specific
    â”‚                           â”‚
    â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Search ALL  â”‚          â”‚ Single set  â”‚
â”‚ doc sets?   â”‚          â”‚ sufficient â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                           â”‚
    â–¼                           â–¼
Multiple results           Verify specific
from various sets          terms covered
    â”‚                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Document Coverage   â”‚
        â”‚ - What's covered     â”‚
        â”‚ - What's not         â”‚
        â”‚ - Gaps identified    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Return Format with Coverage Notes

```markdown
Found N relevant document(s) in <doc_set>:

1. **Document Title** - Relevance: why it matches
2. **Another Title** - Relevance: contains section about topic

**Coverage:**
- âœ… Covered: [aspects covered by results]
- âš ï¸  Not covered: [aspects that may exist in other documents]
- ğŸ’¡ Suggestion: [if applicable, suggest other doc sets to search]
```

#### Example: Comprehensive vs Incomplete Search

**Query:** "Claude Code best practices"

**âŒ Incomplete search (what was done before):**
- Single doc set: Claude_Code_Docs:latest
- 2 documents found: Quickstart, Common workflows
- Missing: Agent Skills, Settings, CLI reference

**âœ… Comprehensive search (correct approach):**
- Recognize "best practices" is a generic concept
- Search ALL doc sets for "best practices", "tips", "optimization"
- Results from multiple sources:
  - Quickstart (Pro tips for beginners)
  - Common workflows (best practices section)
  - Agent Skills (skill usage best practices)
  - CLI reference (efficient CLI usage)
  - Settings (configuration best practices)

**Coverage note:** "Found 5 documents covering workflows, skills, configuration, and CLI usage. Performance optimization best practices may be in additional documentation."

## Delegation Pattern

This skill is designed to work with the `doc-retriever` agent and `md-doc-query-optimizer` skill in a multi-phase retrieval workflow:

**Workflow:**
```
Phase 0: Query Optimization (md-doc-query-optimizer)
    â”‚ Input: Raw user query
    â”‚ Output: 3-5 optimized queries with annotations
    â–¼
Phase 1: Document Discovery (this skill - md-doc-searcher)
    â”‚ Input: Optimized queries from Phase 0
    â”‚ Output: Document titles with TOC paths
    â–¼
Phase 2: Content Extraction (md-doc-reader)
    â”‚ Input: Document titles
    â”‚ Output: Full content + line count
    â–¼
Phase 3: Post-Processing (md-doc-processor) [Conditional]
```

When the `doc-retriever` agent needs to find documents:

1. **Receive optimized queries** - Input from `md-doc-query-optimizer` (3-5 queries with strategy annotations)
2. **List available doc sets** - Use `ls -1 md_docs/`
3. **Apply intent filtering** - Filter doc sets based on optimized queries:
   - Extract domain keywords from optimized queries
   - Explicit mentions (e.g., "Claude" â†’ `*Claude*`)
   - Domain-specific terms (e.g., "hooks" â†’ Claude Code context)
   - **NEW: Check for generic/cross-cutting patterns** (e.g., "best practices" â†’ search ALL sets)
   - Ask user if ambiguous
4. **List directories in selected set(s)** - Use `Glob` or `Bash(ls)` with full path
5. **Read docTOC.md for context** - Use `Read` tool to get table of contents
6. **Multi-query semantic matching** - Search with ALL optimized queries:
   - For each optimized query, perform semantic matching
   - Aggregate results from all queries
   - Deduplicate by document title
   - Rank by relevance (documents matched by multiple queries rank higher)
7. **Apply progressive fallback** - Trigger Level 2 (TOC grep) or Level 3 (cross-set) if needed
8. **Verify coverage completeness** - CRITICAL: Check if search is comprehensive
   - Assess query type (generic vs framework-specific)
   - Check result diversity
   - Identify gaps and expand search if needed
9. **Return comprehensive list with coverage notes** - Provide exhaustive list with what is/isn't covered
10. **Delegate to md-doc-reader** - Extract content from found documents

**Critical:** Always specify the documentation set path when listing directories:
- âœ… `find md_docs/Claude_Code_Docs:latest -type d -mindepth 1`
- âŒ `find md_docs -type d -mindepth 2` (too broad, searches all sets)

## Workflow Example

**Input from md-doc-query-optimizer:**
```
Optimized Queries (Ranked):
1. "skills" - direct match
2. "Agent Skills" - context-specific expansion
3. "skills reference" - expansion
```

**Step 1:** åˆ—å‡ºæ–‡æ¡£é›†å¹¶æ ¹æ®æ„å›¾è¿‡æ»¤
```bash
# åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£é›†
ls -1 md_docs/
# Output:
# Claude_Code_Docs:latest
# Python_Docs:3.11
# React_Docs:v18

# æ ¹æ®ä¼˜åŒ–æŸ¥è¯¢è¿‡æ»¤ï¼šæ‰€æœ‰æŸ¥è¯¢éƒ½æŒ‡å‘ "skills" â†’ Claude Code context
# ç›®æ ‡æ–‡æ¡£é›†: Claude_Code_Docs:latest
```

**Step 2:** åœ¨æŒ‡å®šæ–‡æ¡£é›†ä¸­åˆ—å‡ºæ‰€æœ‰ç›®å½•
```bash
ls -1 md_docs/Claude_Code_Docs:latest/

# Returns:
# Agent Skills/
# CLI reference/
# Hooks reference/
# ...
```

**Step 3:** å¤šæŸ¥è¯¢è¯­ä¹‰åŒ¹é…

è¯»å–ç›¸å…³æ–‡æ¡£çš„ `docTOC.md` è·å–æ›´å¤šä¸Šä¸‹æ–‡ï¼š
```bash
# Read md_docs/Claude_Code_Docs:latest/Agent Skills/docTOC.md
```

ä½¿ç”¨è¯­ä¹‰ç†è§£è¿›è¡ŒåŒ¹é…ï¼š
- æŸ¥è¯¢ 1 "skills" â†’ åŒ¹é… "Agent Skills"
- æŸ¥è¯¢ 2 "Agent Skills" â†’ åŒ¹é… "Agent Skills" (é«˜ç›¸å…³åº¦)
- æŸ¥è¯¢ 3 "skills reference" â†’ åŒ¹é… "Agent Skills"
- èšåˆç»“æœå¹¶å»é‡ï¼š{"Agent Skills"}
- æŒ‰åŒ¹é…æŸ¥è¯¢æ•°é‡æ’åºï¼šAgent Skills (matched by 3 queries)

**è¿”å›ç»“æœæ ¼å¼ï¼š**
```
Found 1 relevant document(s):

1. **Agent Skills** - Relevance: Matched by 3 optimized queries (skills, Agent Skills, skills reference)
```

**Step 4:** å§”æ‰˜ç»™ md-doc-reader æŸ¥çœ‹å®Œæ•´ TOC
```python
# ä½¿ç”¨ md-doc-reader skill æŸ¥çœ‹ TOC ç»“æ„
from doc4llm.tool.md_doc_extractor import MarkdownDocExtractor
extractor = MarkdownDocExtractor()
toc = extractor.extract_by_title("Agent Skills")
```

**Step 5:** è¿”å›ç»“æœæ—¶å§‹ç»ˆåŒ…å« Sources

æ‰€æœ‰æœç´¢ç»“æœéƒ½å¿…é¡»åŒ…å« Sources éƒ¨åˆ†ï¼š

```markdown
Found 1 relevant document(s):

1. **Agent Skills** - Relevance: Matched by 3 optimized queries

**Coverage:**
- âœ… Covered: Skills design philosophy and working principles
- âŒ Not covered: Best practices for skill authoring

### æ–‡æ¡£æ¥æº (Sources)

1. **Agent Skills**
   - åŸæ–‡é“¾æ¥: https://code.claude.com/docs/en/agent-skills
   - TOC è·¯å¾„: `md_docs/Claude_Code_Docs:latest/Agent Skills/docTOC.md`

**Note:** Use `/md-doc-reader "Agent Skills"` to view the full TOC and document structure.
```

### Workflow Example: Progressive Fallback in Action

**Input from md-doc-query-optimizer:**
```
Optimized Queries (Ranked):
1. "configure hooks deployment" - decomposition
2. "hooks configuration" - translation
3. "deployment hooks" - decomposition
4. "setup hooks" - expansion
```

**Step 1:** åˆ—å‡ºæ–‡æ¡£é›†å¹¶æ ¹æ®æ„å›¾è¿‡æ»¤
```bash
ls -1 md_docs/
# Output: Claude_Code_Docs:latest
# æ ¹æ®ä¼˜åŒ–æŸ¥è¯¢è¿‡æ»¤ï¼šæ‰€æœ‰æŸ¥è¯¢éƒ½æŒ‡å‘ "hooks" â†’ Claude Code context
# ç›®æ ‡æ–‡æ¡£é›†: Claude_Code_Docs:latest
```

**Step 2:** åœ¨æŒ‡å®šæ–‡æ¡£é›†ä¸­åˆ—å‡ºæ‰€æœ‰ç›®å½•
```bash
ls -1 md_docs/Claude_Code_Docs:latest/
# Returns many directories
```

**Step 3:** å¤šæŸ¥è¯¢è¯­ä¹‰åŒ¹é…ï¼ˆLevel 1ï¼‰

```bash
# Multi-query semantic match on titles
# Result: Found matches with varying similarity
# Query 1 "configure hooks deployment" â†’ max_sim = 0.5 (low)
# Query 2 "hooks configuration" â†’ max_sim = 0.6 (low)
# Query 3 "deployment hooks" â†’ max_sim = 0.55 (low)
# Query 4 "setup hooks" â†’ max_sim = 0.58 (low)
```

**Decision:** max_similarity (0.6) < threshold (0.7) â†’ **Trigger Level 2 fallback**

**Step 3.5:** è§¦å‘æ¸è¿›å¼å›é€€ç­–ç•¥

**Level 1 quality insufficient â†’ è¿›å…¥ Level 2**

ä»ä¼˜åŒ–æŸ¥è¯¢ä¸­æå–æ ¸å¿ƒå…³é”®è¯: `configure`, `hooks`, `deployment`, `setup`

```bash
# Level 2: TOC grep fallback
grep -r -iE "(configure|hooks|deployment|setup)" md_docs/Claude_Code_Docs:latest/*/docTOC.md
```

**Result:** Found matches in TOC files
```
md_docs/Claude_Code_Docs:latest/Hooks reference/docTOC.md:   ## Configure hooks
md_docs/Claude_Code_Docs:latest/Get started with Claude Code hooks/docTOC.md:   ## Deployment hooks
```

**è¿”å›ç»“æœ:**
```
Found 2 relevant document(s) via Level 2 fallback:

1. **Hooks reference** - Relevance: TOC contains "Configure hooks" section (matched by queries 1, 2, 4)
2. **Get started with Claude Code hooks** - Relevance: TOC contains "Deployment hooks" section (matched by queries 1, 3)
```

**Level 3 æœªè§¦å‘** (Level 2 å·²è¿”å›ç»“æœ)

**Step 4:** è¿”å›ç»“æœå¹¶åŒ…å« Sourcesï¼ˆå§‹ç»ˆå¿…éœ€ï¼‰

è¿”å›æ—¶å¿…é¡»åŒ…å« Sourcesï¼š

```markdown
Found 2 relevant document(s) via Level 2 fallback:

1. **Hooks reference** - Relevance: TOC contains "Configure hooks" section
2. **Get started with Claude Code hooks** - Relevance: TOC contains "Deployment hooks" section

**Coverage:**
- âœ… Covered: Hooks configuration and deployment
- âŒ Not covered: Advanced hooks patterns

### æ–‡æ¡£æ¥æº (Sources)

1. **Hooks reference**
   - åŸæ–‡é“¾æ¥: https://code.claude.com/docs/en/hooks
   - TOC è·¯å¾„: `md_docs/Claude_Code_Docs:latest/Hooks reference/docTOC.md`

2. **Get started with Claude Code hooks**
   - åŸæ–‡é“¾æ¥: https://code.claude.com/docs/en/hooks-get-started
   - TOC è·¯å¾„: `md_docs/Claude_Code_Docs:latest/Get started with Claude Code hooks/docTOC.md`

**Note:** Use `/md-doc-reader "Hooks reference"` to view the full TOC and document structure.
```

---

**âš ï¸ Updated Logic (v2.2):** Major improvements to progressive fallback:
1. **Level 2** is triggered when: No results OR low quality matches (max_similarity < 0.7)
2. **Level 3.1** adds domain relevance filtering for cross-set TOC searches
3. **Level 3.2** adds context traceback for content searches (grep -B 10, title from 5 lines with retry)
4. **All results** now include TOC paths instead of content paths
5. **Sources section** is now always required regardless of document length

This ensures:
- Cross-set searches respect the user's query domain
- Content searches provide proper attribution without loading full files
- All results point to docTOC.md for follow-up via md-doc-reader

---

## More Intent Filtering Examples

**Example 1: Explicit framework mention**
```
User: "æŸ¥æ‰¾ Python ä¸­å…³äºè£…é¥°å™¨çš„æ–‡æ¡£"

Intent filtering:
  â†’ User mentioned "Python"
  â†’ Filter doc sets to: *Python*
  â†’ Selected: Python_Docs:3.11

Results:
  - Python Decorators
  - Functions (contains decorator info)
```

**Example 2: Implicit context**
```
User: "å¦‚ä½•é…ç½® hooks"

Intent analysis:
  â†’ "hooks" is Claude Code specific terminology
  â†’ Filter doc sets to: *Claude*
  â†’ Selected: Claude_Code_Docs:latest

Results:
  - Hooks reference
  - Get started with Claude Code hooks
```

**Example 3: Ambiguous query**
```
User: "æŸ¥æ‰¾å…³äºéƒ¨ç½²çš„æ–‡æ¡£"

Intent analysis:
  â†’ "deployment" is generic term
  â†’ Multiple doc sets may contain this info
  â†’ Ask user: "æ‚¨æƒ³æŸ¥æ‰¾å“ªä¸ªé¡¹ç›®çš„éƒ¨ç½²æ–‡æ¡£ï¼Ÿ"
  â†’ User clarifies: "Claude Code"
  â†’ Proceed with Claude_Code_Docs:latest
```

**Example 4: Cross-cutting concept (Multi-Set Search) - NEW**
```
User: "Claude Code best practices"

Intent analysis:
  â†’ "best practices" is a generic/cross-cutting concept
  â†’ Could apply to: workflows, skills, configuration, CLI usage, etc.
  â†’ Action: Search ALL doc sets for "best practices" OR related terms

Step 1: List all doc sets
```bash
ls -1 md_docs/
# Claude_Code_Docs:latest
# Python_Docs:3.11
# React_Docs:v18
# ...
```

Step 2: Recognize generic pattern - "best practices"
â†’ This is NOT framework-specific
â†’ Multi-set search is REQUIRED

Step 3: Comprehensive search across all sets
```bash
# Search Claude_Code_Docs:latest
grep -r -iE "(best.practice|tips|optimization|guide)" "md_docs/Claude_Code_Docs:latest/*/docTOC.md"

# Results from Claude_Code_Docs:latest:
# - Quickstart (Pro tips for beginners)
# - Common workflows (best practices section)
# - Agent Skills (skill usage best practices)
# - CLI reference (efficient CLI usage)
# - Claude Code settings (configuration best practices)
```

**Coverage verification:**
- âœ… Workflows and usage patterns covered
- âœ… Skills and configuration covered
- âœ… CLI best practices covered
- âš ï¸  Performance optimization may need additional search

**Return with coverage notes:**
```
Found 5 relevant document(s) in Claude_Code_Docs:latest:

1. **Quickstart** - Relevance: Contains "Pro tips for beginners" section
2. **Common workflows** - Relevance: Contains explicit "best practices" guidance
3. **Agent Skills** - Relevance: Covers skill usage best practices
4. **CLI reference** - Relevance: Contains efficient CLI usage patterns
5. **Claude Code settings** - Relevance: Configuration best practices

**Coverage:**
- âœ… Covered: Workflows, skills, configuration, CLI usage patterns
- âš ï¸  Partially covered: Performance optimization (check individual workflow docs)
- ğŸ’¡ For advanced optimization techniques, consider searching for "performance" or "optimization" specifically
```

**Key difference from Example 3:**
- Example 3 (deployment): Ambiguous but context-specific â†’ Ask user to clarify
- Example 4 (best practices): Generic/cross-cutting â†’ Comprehensive multi-set search automatically
```

**Example 5: Configuration/setup (Multi-Set Search)**
```
User: "how to configure authentication"

Intent analysis:
  â†’ "configure" + "authentication" = setup/configuration pattern
  â†’ Could be framework-specific OR generic
  â†’ Action: Start with context inference, then expand

Step 1: Check for context
â†’ Previous messages about Claude Code? â†’ Search Claude_Code_Docs:latest
â†’ No context? â†’ Multi-set search

Step 2: Multi-set search (no context)
```bash
# Search multiple sets for "configure" + "authentication"
for doc_set in md_docs/*/; do
  grep -r -iE "(configure.*auth|authentication.*config|setup.*auth)" "$doc_set"*/docTOC.md
done
```

Results could include:
- Claude_Code_Docs:latest â†’ "Claude Code settings" (authentication configuration)
- Python_Docs:3.11 â†’ "Authentication" (Python-specific auth setup)
- Generic docs â†’ "Security configuration" patterns

**Return format:**
```
Found 3 relevant document(s) across multiple doc sets:

1. **Claude Code settings** (Claude_Code_Docs:latest)
   - Relevance: Authentication configuration for Claude Code
2. **Authentication** (Python_Docs:3.11)
   - Relevance: Python authentication setup patterns
3. **Security** (General_Docs)
   - Relevance: Generic authentication configuration

**Coverage:**
- âœ… Claude Code authentication: Covered
- âœ… Python authentication: Covered
- âœ… Generic security patterns: Covered
- ğŸ’¡ Specify your framework for targeted results
```

## Search Scope Control

**Important:** Always limit searches to specific docTOC.md files within a documentation set:

| Method | Command | Scope |
|--------|---------|-------|
| **Incorrect** | `find md_docs -type d -mindepth 2` | Searches ALL documentation sets (directories) |
| **Incorrect** | `md_docs/Claude_Code_Docs:latest/*/` | Returns directories, not TOC files |
| **Correct** | `find md_docs/Claude_Code_Docs:latest -name "docTOC.md"` | Searches ONLY TOC files in specified set |
| **Correct** | Glob `md_docs/Claude_Code_Docs:latest/*/docTOC.md` | Searches ONLY TOC files in specified set |

**Why this matters:**
- Prevents cross-contamination between different documentation sets
- Ensures accurate semantic matching within the correct domain
- Improves search performance by reducing search space
- Follows **progressive disclosure** - TOC first, content later via md-doc-reader

## Keyword Extraction for Fallback Searches

When invoking Level 2 or Level 3 fallback, extract core keywords from user query:

### Extraction Rules

| Rule | Example | Extracted Keywords |
|------|---------|-------------------|
| Remove stop words | "how to configure hooks" | configure, hooks |
| Preserve technical terms | "API authentication with JWT" | API, authentication, JWT |
| Use root forms | "deploying, deployed, deployment" | deploy |
| Remove question words | "what is the best way to" | best, way |
| Split compound terms | "webhook configuration" | webhook, configuration |

### Stop Words to Remove

**Common stop words:** the, a, an, and, or, but, is, are, was, were, to, for, with, by, from, at, on, in, about, how, what, where, when, why, which, that, this, these, those

**Preserve:** API, CLI, SDK, HTTP, JWT, OAuth, hooks, config, deploy, auth, token, endpoint, webhook, middleware, etc.

### Extraction Examples

| User Query | Extracted Keywords | Grep Command |
|------------|-------------------|--------------|
| "how to configure hooks for deployment" | configure, hooks, deployment | `grep -r -iE "(configure|hooks|deployment)"` |
| "API authentication with JWT tokens" | API, authentication, JWT, tokens | `grep -r -iE "(API|authentication|JWT|tokens)"` |
| "what is the best way to deploy" | best, way, deploy | `grep -r -iE "(best|way|deploy)"` |
| "webhook configuration guide" | webhook, configuration, guide | `grep -r -iE "(webhook|configuration|guide)"` |
