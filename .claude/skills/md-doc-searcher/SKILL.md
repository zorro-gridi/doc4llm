---
name: md-doc-searcher
description: Search and discover markdown documents in the doc4llm md_docs directory using semantic understanding. Use this skill when Claude needs to find documents matching a query, list available documentation, search document titles by understanding user intent, or discover which documentation sets contain relevant content. Performs comprehensive search across relevant documentation sets and returns exhaustive list of relevant document titles with coverage verification.
allowed-tools:
  - Read
  - Glob
  - Bash
---

# Markdown Document Searcher

Search and discover markdown documents in the doc4llm md_docs directory structure using semantic matching.

This skill focuses on **document discovery** - finding which documents match your query. For content extraction, use the `md-doc-reader` skill.

## Quick Start

When a user requests document search, follow this workflow:

1. **List documentation sets** - Use `ls -1 md_docs/` and **filter based on user's query intent**
2. **Select target set(s)** - Choose the most relevant documentation set(s). For generic/cross-cutting queries, consider searching MULTIPLE sets.
3. **List document directories** - Use `Glob` or `Bash(ls)` in the selected set(s)
4. **Read docTOC.md files** - Use `Read` tool to get table of contents for context
5. **Semantic matching** - Use language understanding to match query with document titles
6. **Apply progressive fallback** - If Level 1 returns insufficient results, trigger Level 2 (TOC grep) then Level 3 (cross-set search)
7. **Verify coverage completeness** - CRITICAL: Check if search results are comprehensive. Expand search if gaps exist.
8. **Return comprehensive list** - Provide exhaustive list with coverage notes indicating what is/isn't covered

**Example:**
```
User: "æŸ¥æ‰¾å…³äºé…ç½® Claude Code çš„æ–‡æ¡£"

Step 1: List and filter doc sets
  â†’ Available: Claude_Code_Docs:latest, Python_Docs:3.11, ...
  â†’ Filter: User mentioned "Claude Code" â†’ Select Claude_Code_Docs:latest

Step 2-6: Search within Claude_Code_Docs:latest
  â†’ Semantic match for "é…ç½®" (configuration)
  â†’ Results:
    - Claude Code settings
    - Model configuration
```

## Discovery Workflow

### Step 1: Identify Documentation Set with Intent Filtering

First, list available documentation sets and **filter based on user's query intent**:

```bash
# List all available documentation sets
ls -1 md_docs/

# Example output:
# Claude_Code_Docs:latest/
# Python_Docs:3.11/
# React_Docs:v18/
# Another_Doc:v1.0/
```

**Intent-Based Filtering:**
- If user mentions "Claude", "Claude Code" â†’ Filter to `*Claude*` sets
- If user mentions "Python" â†’ Filter to `*Python*` sets
- If user mentions specific framework â†’ Filter to matching sets
- If no specific mention â†’ Ask user to clarify or search all sets

**Examples:**

| User Query | Filter To | Reason |
|------------|-----------|--------|
| "Claude Code ä¸­å…³äº skills çš„æ–‡æ¡£" | `Claude_Code_Docs:latest` | User explicitly mentioned Claude Code |
| "Python å¼‚å¸¸å¤„ç†æ–‡æ¡£" | `*Python*` | User mentioned Python |
| "å¦‚ä½•é…ç½® hooks" | `Claude_Code_Docs:latest` (context) | "hooks" suggests Claude Code context |
| "æ‰€æœ‰å…³äº deployment çš„æ–‡æ¡£" | Ask user | Multiple sets may contain deployment info |

**Commands for filtered listing:**
```bash
# List all sets (for context)
ls -1 md_docs/

# Filter by pattern (e.g., Claude-related)
ls -1 md_docs/ | grep -i claude

# Or use Glob
md_docs/*Claude*/
```

**Important:** Always search within a **specific documentation set** to ensure accurate results. If multiple sets match the query, ask the user to confirm which one to search.

### Step 2: List Document Directories in Specified Set

Use `Glob` or `Bash(find)` to discover document directories **within the specified set**:

```bash
# Method 1: Using find with path restriction
find md_docs/Claude_Code_Docs:latest -type d -mindepth 1

# Method 2: Using Glob pattern
md_docs/Claude_Code_Docs:latest/*/

# Expected structure:
# md_docs/<doc_name>:<doc_version>/<PageTitle>/
```

**Key point:** Specify the full path including the documentation set to limit search scope.

### Step 3: Semantic Matching (via Prompt)

After listing directories, use **semantic understanding via prompt instructions** to match the user's query:

1. **Read docTOC.md files** - For better context, read table of contents from each document
2. **Use new TOC processing utilities** - Extract and match TOC sections using the new utility functions
3. **Semantic matching** - Use your language understanding to match query intent with document content
4. **Return matching directories** - List relevant document paths based on semantic relevance

**Important:** Do NOT rely on simple keyword matching. Use your semantic understanding to:
- Match related concepts (e.g., "configuration" â†’ "settings", "setup")
- Understand domain-specific terminology
- Consider context and user intent

**New in v2.0:** TOC Processing Utilities

The `utils` module now provides enhanced TOC processing functions:

```python
from doc4llm.tool.md_doc_extractor.utils import extract_toc_sections, semantic_match_toc_sections

# Extract sections from docTOC.md content
sections = extract_toc_sections(toc_content, query="hooks", max_sections=20)
# Returns: [{'level': 2, 'title': 'Configure hooks', 'anchor': 'configure-hooks', 'line_number': 5}]

# Or semantic match existing sections
matched = semantic_match_toc_sections(sections, "hooks")
# Returns sections sorted by relevance score
```

**TOC Extraction Workflow:**
1. Read `docTOC.md` file using `Read` tool
2. Parse sections using `extract_toc_sections()` - extracts level, title, anchor, line_number
3. Optionally filter by query or relevance using `semantic_match_toc_sections()`
4. Return matched sections with relevance scores

**Benefits:**
- Structured TOC parsing with metadata
- Semantic matching on section titles
- Anchor link generation for navigation
- Line number tracking for debugging

### Step 3.5: Progressive Fallback Strategy (NEW)

When Level 1 semantic matching returns **0 results OR low-quality matches** (max_similarity < 0.7), automatically invoke fallback levels:

#### Level 1: Semantic Title Matching (Default)
- Current implementation
- Fast path for well-titled documents
- **Quality threshold:** `max_similarity >= 0.7` to return results

#### Level 2: TOC Content Grep (Fallback)

**Trigger:** Level 1 returns 0 results **OR** `max_similarity < 0.7` (low quality matches)

**Command:**
```bash
# Extract core keywords from query and grep TOC files
grep -r -i "core_keyword" md_docs/<doc_set>/*/docTOC.md
```

**Keyword Extraction Rules:**
- Remove stop words: the, a, an, how, to, for, with, by, from, at, on, in, about
- Preserve technical terms: API, hooks, JWT, OAuth, CLI, SDK, HTTP, etc.
- Use root form: configure â†’ config, authenticate â†’ auth, deploy â†’ deployment

**Example:**
```
Query: "how to configure hooks for deployment"
Keywords extracted: configure, hooks, deployment
Grep command: grep -r -iE "(configure|hooks|deployment)" md_docs/<doc_set>/*/docTOC.md
```

#### Level 3: Cross-Set + Full Content (Last Resort)

**Trigger:** Level 2 returns 0 results

**Commands:**
```bash
# Cross-set TOC search
grep -r -i "keyword" md_docs/*/docTOC.md

# If still empty, content search
grep -r -i "keyword" md_docs/*/docContent.md
```

**Note:** This is the slowest but provides maximum recall. Only invoke when Level 1 and Level 2 both return 0 results.

### Step 4: Delegate to md-doc-reader

Once relevant directories are found, delegate content extraction to `md-doc-reader` skill.

## Semantic Search Instructions

When performing document search, follow these guidelines:

### 1. Intent Filtering at Documentation Set Level

First level of filtering - determine which documentation set to search:

**Filtering Strategies:**

| Strategy | When to Use | Example |
|----------|-------------|---------|
| **Explicit mention** | User names the framework | "Python" â†’ `*Python*` sets |
| **Domain-specific terms** | Unique terminology maps to specific set | "hooks" â†’ Claude Code |
| **Context inference** | Current session context | Previous question about React â†’ React docs |
| **Ask user** | Ambiguous or multiple matches | "deployment" â†’ Ask which project |

**Commands:**
```bash
# List all doc sets
ls -1 md_docs/

# Filter by pattern
ls -1 md_docs/ | grep -i python

# Check if specific set exists
ls -1 md_docs/ | grep -i claude
```

### 2. Use Semantic Understanding, Not Keyword Matching

**âŒ Avoid:** Simple keyword/substring matching
**âœ… Use:** Language understanding to match concepts and context

### 3. Read docTOC.md for Context

Before matching, read the `docTOC.md` file to understand the document structure:
```
Read: md_docs/<doc_set>/<PageTitle>/docTOC.md
```

### 4. Consider Synonyms and Related Concepts

| User Query | Should Match |
|------------|--------------|
| "how to configure" | Settings, Configuration, Setup, Preferences |
| "deployment" | Enterprise deployment, Install, Setup |
| "security" | Authentication, Authorization, Security settings |
| "API" | API reference, Connect, Integration |

### 5. Return Format

Return results as a list of document titles with relevance notes AND coverage verification:

```
Found N relevant document(s) in <doc_set>:

1. **Document Title** - Relevance: why it matches
2. **Another Title** - Relevance: contains section about topic
...

**Coverage:**
- âœ… Covered: [aspects covered by results]
- âš ï¸  Partially covered: [aspects partially covered]
- âŒ Not covered: [aspects that may exist in other documents/sets]
- ğŸ’¡ Suggestion: [if applicable, suggest other searches]
```

**Example with coverage notes:**
```
Found 3 relevant document(s) in Claude_Code_Docs:latest:

1. **Quickstart** - Relevance: Contains "Pro tips for beginners" section
2. **Common workflows** - Relevance: Contains explicit "best practices" guidance
3. **Agent Skills** - Relevance: Covers skill usage best practices

**Coverage:**
- âœ… Covered: Workflow best practices, skill usage patterns
- âš ï¸  Partially covered: Configuration best practices (check Settings doc)
- âŒ Not covered: Performance optimization, security best practices
- ğŸ’¡ Suggestion: Search "performance" or "security" for those topics
```

### 6. Sources Format (REQUIRED when returning content)

**IMPORTANT:** If you extract and return document content (e.g., when document is â‰¤ 1000 lines or user explicitly requests full content), you MUST include a **Sources** section at the end.

This is the same format requirement as `md-doc-processor` skill - see that skill's documentation for full details.

#### Required Format

```markdown

---

### æ–‡æ¡£æ¥æº (Sources)

1. **Document Title**
   - åŸæ–‡é“¾æ¥: https://original-url.com/docs/page
   - è·¯å¾„: `md_docs/<doc_name>:<doc_version>/<PageTitle>/docContent.md`
```

#### Example

```markdown
# Common workflows

[Content...]

### æ–‡æ¡£æ¥æº (Sources)

1. **Common workflows**
   - åŸæ–‡é“¾æ¥: https://code.claude.com/docs/en/common-workflows
   - è·¯å¾„: `md_docs/Claude_Code_Docs:latest/Common workflows/docContent.md`
```

#### How to Get Source Information

1. **Original URL**: Found at the top of docContent.md:
   ```markdown
   > **åŸæ–‡é“¾æ¥**: https://code.claude.com/docs/en/common-workflows
   ```

2. **Local Path**: `md_docs/<doc_name>:<doc_version>/<PageTitle>/docContent.md`

## Directory Structure

Expected format:
```
md_docs/
â””â”€â”€ <doc_name>:<doc_version>/
    â””â”€â”€ <PageTitle>/
        â”œâ”€â”€ docContent.md    # Main content
        â””â”€â”€ docTOC.md        # Table of contents
```

Each `<PageTitle>` directory represents one document page.

## Progressive Fallback Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEARCH REQUEST                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Level 1: Title Semantic Match â”‚
              â”‚  - List directories            â”‚
              â”‚  - Semantic understanding      â”‚
              â”‚  - Fast: O(k) where k = matchesâ”‚
              â”‚  - Threshold: max_sim >= 0.7   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                               â”‚
        [Results > 0 AND                 [Results = 0 OR
         max_sim >= 0.7]                  max_sim < 0.7]
              â”‚                               â”‚
              â–¼                               â–¼
        To Coverage Check            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  Level 2: TOC Grep Fallback   â”‚
                                    â”‚  - grep -r across TOC files   â”‚
                                    â”‚  - Balanced: O(1) operation   â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚                   â”‚
                              [Results > 0]      [Results = 0]
                                    â”‚                   â”‚
                                    â–¼                   â–¼
                          To Coverage Check    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                  â”‚  Level 3: Max Recall         â”‚
                                                  â”‚  - Cross-set TOC + Content   â”‚
                                                  â”‚  - Slowest but comprehensiveâ”‚
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                            â”‚
                                                            â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚   Coverage Completeness â”‚
                                              â”‚   Verification Check    â”‚
                                              â”‚   - Assess query type   â”‚
                                              â”‚   - Check result diversity
                                              â”‚   - Identify gaps      â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚                           â”‚
                                    [Coverage Complete]          [Gaps Found]
                                    - Generic queries handled   - Expand scope
                                    - All aspects covered      - Search other sets
                                          â”‚                           â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚    Return Results        â”‚
                                          â”‚    With Coverage Notes   â”‚
                                          â”‚    - What's covered       â”‚
                                          â”‚    - What's not           â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Search Completeness Guidelines

### When is Search Considered Complete?

**CRITICAL:** A search is ONLY complete when you have **verified** that all potentially relevant documents have been found. The progressive fallback strategy finds matches within a scope, but you MUST verify coverage completeness.

#### Completeness Checklist

Before returning results, ask yourself:

- [ ] Have I searched ALL relevant documentation sets?
- [ ] Do the results cover different aspects of the query?
- [ ] Could related concepts exist in documents with different titles?
- [ ] Should I cross-reference with other documentation sets?
- [ ] Have I explicitly stated what is/isn't covered in the results?

#### Multi-Set Search Triggers

**ALWAYS search multiple documentation sets when:**

| Query Pattern | Example | Action | Rationale |
|--------------|---------|--------|-----------|
| Generic concepts | "best practices", "tips", "optimization" | Search ALL doc sets | These concepts apply across multiple domains |
| Cross-cutting concerns | "deployment", "testing", "monitoring", "security" | Search ALL doc sets | May have framework-specific and general implementations |
| Configuration/setup | "how to configure", "setup guide", "getting started" | Search ALL doc sets | Setup varies by framework/context |
| Comparison questions | "difference between X and Y", "X vs Y" | Search ALL doc sets | Requires comprehensive comparison |
| Framework-specific | "React hooks", "Python async", "Claude skills" | Single set | Terminology is domain-specific |

#### Coverage Verification Steps

After completing Level 1-3 search:

1. **Assess result diversity** - Do results cover different perspectives/aspects?
2. **Identify gaps** - What aspects of the query are NOT covered?
3. **Expand if needed** - If gaps found, search other doc sets
4. **Document coverage** - Explicitly state what IS and ISN'T covered

#### Decision Tree: Is Coverage Complete?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     After Level 1-3 Search              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Assess Query Type   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           â”‚
Generic/Cross-cutting    Framework-specific
    â”‚                           â”‚
    â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Search ALL  â”‚          â”‚ Single set  â”‚
â”‚ doc sets?   â”‚          â”‚ sufficient â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                           â”‚
    â–¼                           â–¼
Multiple results           Verify specific
from various sets          terms covered
    â”‚                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Document Coverage   â”‚
        â”‚ - What's covered     â”‚
        â”‚ - What's not         â”‚
        â”‚ - Gaps identified    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Return Format with Coverage Notes

```markdown
Found N relevant document(s) in <doc_set>:

1. **Document Title** - Relevance: why it matches
2. **Another Title** - Relevance: contains section about topic

**Coverage:**
- âœ… Covered: [aspects covered by results]
- âš ï¸  Not covered: [aspects that may exist in other documents]
- ğŸ’¡ Suggestion: [if applicable, suggest other doc sets to search]
```

#### Example: Comprehensive vs Incomplete Search

**Query:** "Claude Code best practices"

**âŒ Incomplete search (what was done before):**
- Single doc set: Claude_Code_Docs:latest
- 2 documents found: Quickstart, Common workflows
- Missing: Agent Skills, Settings, CLI reference

**âœ… Comprehensive search (correct approach):**
- Recognize "best practices" is a generic concept
- Search ALL doc sets for "best practices", "tips", "optimization"
- Results from multiple sources:
  - Quickstart (Pro tips for beginners)
  - Common workflows (best practices section)
  - Agent Skills (skill usage best practices)
  - CLI reference (efficient CLI usage)
  - Settings (configuration best practices)

**Coverage note:** "Found 5 documents covering workflows, skills, configuration, and CLI usage. Performance optimization best practices may be in additional documentation."

## Delegation Pattern

This skill is designed to work with the `doc-retriever` agent for document discovery tasks:

1. **Discovery Phase** (this skill): Find matching document directories
2. **Extraction Phase** (`md-doc-reader` skill): Extract content from found documents

When the `doc-retriever` agent needs to find documents:

1. **List available doc sets** - Use `ls -1 md_docs/`
2. **Apply intent filtering** - Filter doc sets based on user's query:
   - Explicit mentions (e.g., "Claude" â†’ `*Claude*`)
   - Domain-specific terms (e.g., "hooks" â†’ Claude Code context)
   - **NEW: Check for generic/cross-cutting patterns** (e.g., "best practices" â†’ search ALL sets)
   - Ask user if ambiguous
3. **List directories in selected set(s)** - Use `Glob` or `Bash(ls)` with full path
4. **Read docTOC.md for context** - Use `Read` tool to get table of contents
5. **Apply semantic matching** - Use language understanding, NOT simple keyword matching
6. **Apply progressive fallback** - Trigger Level 2 (TOC grep) or Level 3 (cross-set) if needed
7. **Verify coverage completeness** - CRITICAL: Check if search is comprehensive
   - Assess query type (generic vs framework-specific)
   - Check result diversity
   - Identify gaps and expand search if needed
8. **Return comprehensive list with coverage notes** - Provide exhaustive list with what is/isn't covered
9. **Delegate to md-doc-reader** - Extract content from found documents

**Critical:** Always specify the documentation set path when listing directories:
- âœ… `find md_docs/Claude_Code_Docs:latest -type d -mindepth 1`
- âŒ `find md_docs -type d -mindepth 2` (too broad, searches all sets)

## Workflow Example

**User query:** "åœ¨ Claude_Code_Docs:latest ä¸­æŸ¥æ‰¾å…³äº skills çš„æ–‡æ¡£"

**Step 1:** åˆ—å‡ºæ–‡æ¡£é›†å¹¶æ ¹æ®æ„å›¾è¿‡æ»¤
```bash
# åˆ—å‡ºæ‰€æœ‰æ–‡æ¡£é›†
ls -1 md_docs/
# Output:
# Claude_Code_Docs:latest
# Python_Docs:3.11
# React_Docs:v18

# æ ¹æ®ç”¨æˆ·æ„å›¾è¿‡æ»¤ï¼šç”¨æˆ·æ˜ç¡®æåˆ° "Claude_Code_Docs:latest"
# ç›®æ ‡æ–‡æ¡£é›†: Claude_Code_Docs:latest
```

**Step 2:** åœ¨æŒ‡å®šæ–‡æ¡£é›†ä¸­åˆ—å‡ºæ‰€æœ‰ç›®å½•
```bash
ls -1 md_docs/Claude_Code_Docs:latest/

# Returns:
# Agent Skills/
# CLI reference/
# Hooks reference/
# ...
```

**Step 3:** è¯­ä¹‰åŒ¹é…ï¼ˆé€šè¿‡ Prompt æŒ‡ä»¤ï¼‰

è¯»å–ç›¸å…³æ–‡æ¡£çš„ `docTOC.md` è·å–æ›´å¤šä¸Šä¸‹æ–‡ï¼š
```bash
# Read md_docs/Claude_Code_Docs:latest/Agent Skills/docTOC.md
```

ä½¿ç”¨è¯­ä¹‰ç†è§£è¿›è¡ŒåŒ¹é…ï¼š
- æŸ¥è¯¢ "skills" â†’ åŒ¹é… "Agent Skills"
- è€ƒè™‘ä¸Šä¸‹æ–‡ï¼šç”¨æˆ·æƒ³è¦äº†è§£ Agent Skills ç›¸å…³å†…å®¹
- è¿”å›åŒ¹é…çš„æ–‡æ¡£æ ‡é¢˜åˆ—è¡¨

**è¿”å›ç»“æœæ ¼å¼ï¼š**
```
Found 1 relevant document(s):

1. **Agent Skills** - Relevance: Direct match for "skills" query
```

**Step 4:** å§”æ‰˜ç»™ md-doc-reader æå–å†…å®¹
```python
# ä½¿ç”¨ md-doc-reader skill æå–å†…å®¹
from doc4llm.tool.md_doc_extractor import MarkdownDocExtractor
extractor = MarkdownDocExtractor()
content = extractor.extract_by_title("Agent Skills")
```

**Step 5:** è¿”å›å†…å®¹æ—¶åŒ…å« Sources

å¦‚æœç›´æ¥è¿”å›å†…å®¹ï¼ˆæ–‡æ¡£ â‰¤ 1000 è¡Œæˆ–ç”¨æˆ·è¯·æ±‚å®Œæ•´å†…å®¹ï¼‰ï¼Œå¿…é¡»æ·»åŠ  Sources éƒ¨åˆ†ï¼š

```markdown
# Agent Skills

[æ–‡æ¡£å†…å®¹...]

### æ–‡æ¡£æ¥æº (Sources)

1. **Agent Skills**
   - åŸæ–‡é“¾æ¥: https://code.claude.com/docs/en/agent-skills
   - è·¯å¾„: `md_docs/Claude_Code_Docs:latest/Agent Skills/docContent.md`
```

### Workflow Example: Progressive Fallback in Action

**User query:** "æŸ¥æ‰¾å¦‚ä½•é…ç½® hooks è¿›è¡Œéƒ¨ç½²"
*(Query: "Find how to configure hooks for deployment")*

**Step 1:** åˆ—å‡ºæ–‡æ¡£é›†å¹¶æ ¹æ®æ„å›¾è¿‡æ»¤
```bash
ls -1 md_docs/
# Output: Claude_Code_Docs:latest
# ç›®æ ‡æ–‡æ¡£é›†: Claude_Code_Docs:latest
```

**Step 2:** åœ¨æŒ‡å®šæ–‡æ¡£é›†ä¸­åˆ—å‡ºæ‰€æœ‰ç›®å½•
```bash
ls -1 md_docs/Claude_Code_Docs:latest/
# Returns many directories, but none directly match "configure hooks for deployment"
```

**Step 3:** è¯­ä¹‰åŒ¹é…ï¼ˆLevel 1ï¼‰
```bash
# Semantic match on titles
# Result: Found 1 match with low similarity (max_sim = 0.5)
# Example: "Hooks" â†’ similarity: 0.5
```

**Decision:** max_sim (0.5) < threshold (0.7) â†’ **Trigger Level 2 fallback**

**Step 3.5:** è§¦å‘æ¸è¿›å¼å›é€€ç­–ç•¥

**Level 1 quality insufficient â†’ è¿›å…¥ Level 2**

æå–æ ¸å¿ƒå…³é”®è¯: `configure`, `hooks`, `deployment`

```bash
# Level 2: TOC grep fallback
grep -r -iE "(configure|hooks|deployment)" md_docs/Claude_Code_Docs:latest/*/docTOC.md
```

**Result:** Found matches in TOC files
```
md_docs/Claude_Code_Docs:latest/Hooks reference/docTOC.md:   ## Configure hooks
md_docs/Claude_Code_Docs:latest/Get started with Claude Code hooks/docTOC.md:   ## Deployment hooks
```

**è¿”å›ç»“æœ:**
```
Found 2 relevant document(s) via Level 2 fallback:

1. **Hooks reference** - Relevance: TOC contains "Configure hooks" section
2. **Get started with Claude Code hooks** - Relevance: TOC contains "Deployment hooks" section
```

**Level 3 æœªè§¦å‘** (Level 2 å·²è¿”å›ç»“æœ)

**Step 4:** å§”æ‰˜ç»™ md-doc-reader æå–å†…å®¹å¹¶æ·»åŠ  Sources

```python
# ä½¿ç”¨ md-doc-reader skill æå–å†…å®¹
from doc4llm.tool.md_doc_extractor import MarkdownDocExtractor
extractor = MarkdownDocExtractor()
content = extractor.extract_by_title("Hooks reference")
```

è¿”å›æ—¶åŒ…å« Sourcesï¼š

```markdown
# Hooks Reference

[æ–‡æ¡£å†…å®¹...]

### æ–‡æ¡£æ¥æº (Sources)

1. **Hooks reference**
   - åŸæ–‡é“¾æ¥: https://code.claude.com/docs/en/hooks
   - è·¯å¾„: `md_docs/Claude_Code_Docs:latest/Hooks reference/docContent.md`

2. **Get started with Claude Code hooks**
   - åŸæ–‡é“¾æ¥: https://code.claude.com/docs/en/hooks-get-started
   - è·¯å¾„: `md_docs/Claude_Code_Docs:latest/Get started with Claude Code hooks/docContent.md`
```

---

**âš ï¸ Updated Logic (v2.1):** Level 2 is now triggered when:
1. **No results** (results = 0), OR
2. **Low quality matches** (max_similarity < 0.7)

This ensures better matching by falling back to TOC content search when title-only matching produces insufficient results.

---

## More Intent Filtering Examples

**Example 1: Explicit framework mention**
```
User: "æŸ¥æ‰¾ Python ä¸­å…³äºè£…é¥°å™¨çš„æ–‡æ¡£"

Intent filtering:
  â†’ User mentioned "Python"
  â†’ Filter doc sets to: *Python*
  â†’ Selected: Python_Docs:3.11

Results:
  - Python Decorators
  - Functions (contains decorator info)
```

**Example 2: Implicit context**
```
User: "å¦‚ä½•é…ç½® hooks"

Intent analysis:
  â†’ "hooks" is Claude Code specific terminology
  â†’ Filter doc sets to: *Claude*
  â†’ Selected: Claude_Code_Docs:latest

Results:
  - Hooks reference
  - Get started with Claude Code hooks
```

**Example 3: Ambiguous query**
```
User: "æŸ¥æ‰¾å…³äºéƒ¨ç½²çš„æ–‡æ¡£"

Intent analysis:
  â†’ "deployment" is generic term
  â†’ Multiple doc sets may contain this info
  â†’ Ask user: "æ‚¨æƒ³æŸ¥æ‰¾å“ªä¸ªé¡¹ç›®çš„éƒ¨ç½²æ–‡æ¡£ï¼Ÿ"
  â†’ User clarifies: "Claude Code"
  â†’ Proceed with Claude_Code_Docs:latest
```

**Example 4: Cross-cutting concept (Multi-Set Search) - NEW**
```
User: "Claude Code best practices"

Intent analysis:
  â†’ "best practices" is a generic/cross-cutting concept
  â†’ Could apply to: workflows, skills, configuration, CLI usage, etc.
  â†’ Action: Search ALL doc sets for "best practices" OR related terms

Step 1: List all doc sets
```bash
ls -1 md_docs/
# Claude_Code_Docs:latest
# Python_Docs:3.11
# React_Docs:v18
# ...
```

Step 2: Recognize generic pattern - "best practices"
â†’ This is NOT framework-specific
â†’ Multi-set search is REQUIRED

Step 3: Comprehensive search across all sets
```bash
# Search Claude_Code_Docs:latest
grep -r -iE "(best.practice|tips|optimization|guide)" "md_docs/Claude_Code_Docs:latest/*/docTOC.md"

# Results from Claude_Code_Docs:latest:
# - Quickstart (Pro tips for beginners)
# - Common workflows (best practices section)
# - Agent Skills (skill usage best practices)
# - CLI reference (efficient CLI usage)
# - Claude Code settings (configuration best practices)
```

**Coverage verification:**
- âœ… Workflows and usage patterns covered
- âœ… Skills and configuration covered
- âœ… CLI best practices covered
- âš ï¸  Performance optimization may need additional search

**Return with coverage notes:**
```
Found 5 relevant document(s) in Claude_Code_Docs:latest:

1. **Quickstart** - Relevance: Contains "Pro tips for beginners" section
2. **Common workflows** - Relevance: Contains explicit "best practices" guidance
3. **Agent Skills** - Relevance: Covers skill usage best practices
4. **CLI reference** - Relevance: Contains efficient CLI usage patterns
5. **Claude Code settings** - Relevance: Configuration best practices

**Coverage:**
- âœ… Covered: Workflows, skills, configuration, CLI usage patterns
- âš ï¸  Partially covered: Performance optimization (check individual workflow docs)
- ğŸ’¡ For advanced optimization techniques, consider searching for "performance" or "optimization" specifically
```

**Key difference from Example 3:**
- Example 3 (deployment): Ambiguous but context-specific â†’ Ask user to clarify
- Example 4 (best practices): Generic/cross-cutting â†’ Comprehensive multi-set search automatically
```

**Example 5: Configuration/setup (Multi-Set Search)**
```
User: "how to configure authentication"

Intent analysis:
  â†’ "configure" + "authentication" = setup/configuration pattern
  â†’ Could be framework-specific OR generic
  â†’ Action: Start with context inference, then expand

Step 1: Check for context
â†’ Previous messages about Claude Code? â†’ Search Claude_Code_Docs:latest
â†’ No context? â†’ Multi-set search

Step 2: Multi-set search (no context)
```bash
# Search multiple sets for "configure" + "authentication"
for doc_set in md_docs/*/; do
  grep -r -iE "(configure.*auth|authentication.*config|setup.*auth)" "$doc_set"*/docTOC.md
done
```

Results could include:
- Claude_Code_Docs:latest â†’ "Claude Code settings" (authentication configuration)
- Python_Docs:3.11 â†’ "Authentication" (Python-specific auth setup)
- Generic docs â†’ "Security configuration" patterns

**Return format:**
```
Found 3 relevant document(s) across multiple doc sets:

1. **Claude Code settings** (Claude_Code_Docs:latest)
   - Relevance: Authentication configuration for Claude Code
2. **Authentication** (Python_Docs:3.11)
   - Relevance: Python authentication setup patterns
3. **Security** (General_Docs)
   - Relevance: Generic authentication configuration

**Coverage:**
- âœ… Claude Code authentication: Covered
- âœ… Python authentication: Covered
- âœ… Generic security patterns: Covered
- ğŸ’¡ Specify your framework for targeted results
```

## Search Scope Control

**Important:** Always limit searches to a specific documentation set:

| Method | Command | Scope |
|--------|---------|-------|
| **Incorrect** | `find md_docs -type d -mindepth 2` | Searches ALL documentation sets |
| **Correct** | `find md_docs/Claude_Code_Docs:latest -type d -mindepth 1` | Searches ONLY specified set |
| **Correct** | Glob pattern `md_docs/Claude_Code_Docs:latest/*/` | Searches ONLY specified set |

**Why this matters:**
- Prevents cross-contamination between different documentation sets
- Ensures accurate semantic matching within the correct domain
- Improves search performance by reducing search space

## Keyword Extraction for Fallback Searches

When invoking Level 2 or Level 3 fallback, extract core keywords from user query:

### Extraction Rules

| Rule | Example | Extracted Keywords |
|------|---------|-------------------|
| Remove stop words | "how to configure hooks" | configure, hooks |
| Preserve technical terms | "API authentication with JWT" | API, authentication, JWT |
| Use root forms | "deploying, deployed, deployment" | deploy |
| Remove question words | "what is the best way to" | best, way |
| Split compound terms | "webhook configuration" | webhook, configuration |

### Stop Words to Remove

**Common stop words:** the, a, an, and, or, but, is, are, was, were, to, for, with, by, from, at, on, in, about, how, what, where, when, why, which, that, this, these, those

**Preserve:** API, CLI, SDK, HTTP, JWT, OAuth, hooks, config, deploy, auth, token, endpoint, webhook, middleware, etc.

### Extraction Examples

| User Query | Extracted Keywords | Grep Command |
|------------|-------------------|--------------|
| "how to configure hooks for deployment" | configure, hooks, deployment | `grep -r -iE "(configure|hooks|deployment)"` |
| "API authentication with JWT tokens" | API, authentication, JWT, tokens | `grep -r -iE "(API|authentication|JWT|tokens)"` |
| "what is the best way to deploy" | best, way, deploy | `grep -r -iE "(best|way|deploy)"` |
| "webhook configuration guide" | webhook, configuration, guide | `grep -r -iE "(webhook|configuration|guide)"` |
