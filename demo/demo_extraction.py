"""
æ¼”ç¤ºè„šæœ¬ï¼šä½¿ç”¨æ ‡é¢˜ä» docContent.md æå–æ–‡æ¡£å†…å®¹å’Œç« èŠ‚å†…å®¹
"""
import re
from pathlib import Path

from doc4llm.tool.md_doc_retrieval import (
    MarkdownDocExtractor,
    extract_section_by_title,
)


# é…ç½®è·¯å¾„
# ä» tests/demo_extraction.py åˆ°é¡¹ç›®æ ¹ç›®å½•: tests -> doc4llm
PROJECT_ROOT = Path(__file__).parent.parent
BASE_DIR = PROJECT_ROOT / "md_docs"
DOC_NAME = "code_claude_com"
DOC_VERSION = "latest"
DOC_TITLE = "Agent Skills - Claude Code Docs"

DOC_CONTENT_PATH = BASE_DIR / f"{DOC_NAME}:{DOC_VERSION}" / DOC_TITLE / "docContent.md"
DOC_TOC_PATH = BASE_DIR / f"{DOC_NAME}:{DOC_VERSION}" / DOC_TITLE / "docTOC.md"


def parse_toc_titles(toc_path: Path) -> list[str]:
    """ä» docTOC.md è§£ææ ‡é¢˜åˆ—è¡¨"""
    content = toc_path.read_text(encoding="utf-8")
    titles = []

    for line in content.splitlines():
        line = line.strip()
        match = re.match(r'^(#{2,4})\s+(.+?)\s*ï¼šhttps://', line)
        if match:
            title = match.group(2).strip()
            title = re.sub(r'^\d+(\.\d+)*\.\s+', '', title)
            if title:
                titles.append(title)

    return titles


def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºæ–‡æ¡£å’Œç« èŠ‚æå–"""
    print("=" * 80)
    print("æ–‡æ¡£å†…å®¹æå–æ¼”ç¤º - æ”¯æŒæ–‡æ¡£çº§åˆ«å’Œç« èŠ‚çº§åˆ«æå–")
    print("=" * 80)

    # è¯»å–å®Œæ•´æ–‡æ¡£å†…å®¹
    full_content = DOC_CONTENT_PATH.read_text(encoding="utf-8")

    # è§£ææ‰€æœ‰æ ‡é¢˜
    all_titles = parse_toc_titles(DOC_TOC_PATH)
    print(f"\nğŸ“‹ docTOC.md ä¸­çš„ç« èŠ‚æ ‡é¢˜æ€»æ•°: {len(all_titles)}")

    # é€‰æ‹©å‡ ä¸ªæ ‡é¢˜è¿›è¡Œæµ‹è¯•
    test_titles = [
        "Create your first Skill",
        "How Skills work",
        "Configure Skills",
        "Write SKILL.md",
    ]

    print(f"\nğŸ” æµ‹è¯•ç« èŠ‚æ ‡é¢˜: {test_titles}")
    print("-" * 80)

    # ========================================================================
    # æ–‡æ¡£çº§åˆ«æå–ï¼ˆæ•´ä¸ªæ–‡æ¡£ï¼‰
    # ========================================================================
    print("\nã€ä¸€ã€‘æ–‡æ¡£çº§åˆ«æå– - æå–å®Œæ•´æ–‡æ¡£")
    print("=" * 80)

    extractor = MarkdownDocExtractor(base_dir=str(BASE_DIR))
    doc_content = extractor.extract_by_title(DOC_TITLE)

    print(f"æŸ¥è¯¢æ ‡é¢˜: {DOC_TITLE}")
    print(f"è¿”å›å†…å®¹é•¿åº¦: {len(doc_content)} å­—ç¬¦")
    print(f"å†…å®¹é¢„è§ˆ (å‰150å­—ç¬¦):\n{doc_content[:150]}...")

    # ========================================================================
    # ç« èŠ‚çº§åˆ«æå–ï¼ˆæ–‡æ¡£å†…çš„ç« èŠ‚ï¼‰
    # ========================================================================
    print("\n" + "=" * 80)
    print("ã€äºŒã€‘ç« èŠ‚çº§åˆ«æå– - æå–æ–‡æ¡£å†…çš„ç‰¹å®šç« èŠ‚")
    print("=" * 80)

    for title in test_titles:
        section = extract_section_by_title(full_content, title)
        if section:
            lines = section.splitlines()
            print(f"\nâœ… ç« èŠ‚: {title}")
            print(f"   è¡Œæ•°: {len(lines)} è¡Œ")
            print(f"   å­—ç¬¦æ•°: {len(section)} å­—ç¬¦")
            # æ˜¾ç¤ºå‰3è¡Œä½œä¸ºé¢„è§ˆ
            preview_lines = lines[:3]
            preview = '\n   '.join(preview_lines)
            print(f"   å†…å®¹é¢„è§ˆ:\n   {preview}...")
        else:
            print(f"\nâŒ ç« èŠ‚: {title}")
            print(f"   ç»“æœ: æœªæ‰¾åˆ°åŒ¹é…ç« èŠ‚")

    # ========================================================================
    # å•æ–‡ä»¶æ¨¡å¼ - ç›´æ¥è¯»å–
    # ========================================================================
    print("\n" + "=" * 80)
    print("ã€ä¸‰ã€‘å•æ–‡ä»¶æ¨¡å¼ - ç›´æ¥è¯»å–æ–‡ä»¶")
    print("=" * 80)

    single_extractor = MarkdownDocExtractor(single_file_path=str(DOC_CONTENT_PATH))
    content = single_extractor.extract_by_title()

    print(f"æŸ¥è¯¢æ ‡é¢˜: (æ—  - ç›´æ¥è¯»å–)")
    print(f"è¿”å›å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")

    # ç”¨å•æ–‡ä»¶æ¨¡å¼ + ç« èŠ‚æå–
    print("\n--- å•æ–‡ä»¶æ¨¡å¼ + ç« èŠ‚æå– ---")
    for title in test_titles[:2]:  # åªæµ‹è¯•å‰2ä¸ª
        section = extract_section_by_title(content, title)
        if section:
            print(f"\nâœ… {title}: {len(section)} å­—ç¬¦")

    # ========================================================================
    # æ‰¹é‡æå–å¤šä¸ªç« èŠ‚
    # ========================================================================
    print("\n" + "=" * 80)
    print("ã€å››ã€‘æ‰¹é‡æå–å¤šä¸ªç« èŠ‚")
    print("=" * 80)

    sections = {}
    for title in test_titles:
        section = extract_section_by_title(full_content, title)
        if section:
            sections[title] = section

    print(f"è¯·æ±‚æå– {len(test_titles)} ä¸ªç« èŠ‚")
    print(f"æˆåŠŸæå– {len(sections)} ä¸ªç« èŠ‚:")
    for title, content in sections.items():
        print(f"  - {title}: {len(content)} å­—ç¬¦")

    # ========================================================================
    # ç»Ÿè®¡ä¿¡æ¯
    # ========================================================================
    print("\n" + "=" * 80)
    print("ã€äº”ã€‘ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 80)

    print(f"æ–‡æ¡£æ ‡é¢˜: {DOC_TITLE}")
    print(f"æ–‡æ¡£æ€»é•¿åº¦: {len(full_content)} å­—ç¬¦")
    print(f"æ–‡æ¡£æ€»è¡Œæ•°: {len(full_content.splitlines())} è¡Œ")
    print(f"docTOC.md ç« èŠ‚æ•°: {len(all_titles)} ä¸ª")
    print(f"æˆåŠŸæå–çš„ç« èŠ‚: {len(sections)} ä¸ª")

    # æ‰¾åˆ°æœ€é•¿çš„ç« èŠ‚
    if sections:
        longest = max(sections.items(), key=lambda x: len(x[1]))
        print(f"æœ€é•¿çš„ç« èŠ‚: '{longest[0]}' ({len(longest[1])} å­—ç¬¦)")

    print("\n" + "=" * 80)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)


if __name__ == "__main__":
    main()
